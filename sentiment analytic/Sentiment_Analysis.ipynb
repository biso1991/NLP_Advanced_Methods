{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os , re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "\n",
    "# # Load the dataset from CSV\n",
    "# dataset_path = \"movie_data.csv/movie_data.csv\"\n",
    "# df = pd.read_csv(dataset_path)\n",
    "\n",
    "# # Assuming your CSV has columns named 'review' and 'sentiment'\n",
    "# data = df[['review', 'sentiment']].values.tolist()\n",
    "\n",
    "# # Split the data\n",
    "# train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Create the 'movie_data' directory if it doesn't exist\n",
    "# os.makedirs('movie_data', exist_ok=True)\n",
    "\n",
    "# # Write to train.txt\n",
    "# with open('movie_data/train.txt', 'w', encoding='utf-8') as train_file:\n",
    "#     for item in train_data:\n",
    "#         train_file.write(f\"{item[0]}, {item[1]}\\n\")\n",
    "\n",
    "# # Write to test.txt\n",
    "# with open('movie_data/test.txt', 'w', encoding='utf-8') as test_file:\n",
    "#     for item in test_data:\n",
    "#         test_file.write(f\"{item[0]}, {item[1]}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# directory = 'data/Dataset/2012'\n",
    "\n",
    "# output_file = 'concatenated_output.txt'\n",
    "\n",
    "# text_files = [f for f in os.listdir(directory) if f.endswith('.txt')]\n",
    "\n",
    "# # Open the output file in write mode\n",
    "# with open(output_file, 'w', encoding='utf-8') as output:\n",
    "#     # Iterate over each text file\n",
    "#     for text_file in text_files:\n",
    "#         file_path = os.path.join(directory, text_file)\n",
    "        \n",
    "#         # Read the contents of the text file\n",
    "#         with open(file_path, 'r', encoding='utf-8') as file:\n",
    "#             content = file.read()\n",
    "            \n",
    "#             # Write the content to the output file\n",
    "#             output.write(content)\n",
    "\n",
    "# print(f\"Concatenation complete. Output file: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # Load the dataset from CSV\n",
    "# dataset_path = \"movie_data.csv/movie_data.csv\"\n",
    "# df = pd.read_csv(dataset_path)\n",
    "\n",
    "\n",
    "# data = df[['review', 'sentiment']].values.tolist()\n",
    "\n",
    "# # Split the data\n",
    "# train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Create the 'movie_data' directory if it doesn't exist\n",
    "# os.makedirs('movie_data', exist_ok=True)\n",
    "\n",
    "# # Write to train.txt\n",
    "# with open('movie_data/train.txt', 'w', encoding='utf-8') as train_file:\n",
    "#     for item in train_data:\n",
    "#         train_file.write(f\"{item[0]}, {item[1]}\\n\")\n",
    "\n",
    "# # Write to test.txt\n",
    "# with open('movie_data/test.txt', 'w', encoding='utf-8') as test_file:\n",
    "#     for item in test_data:\n",
    "#         test_file.write(f\"{item[0]}, {item[1]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random\n",
    "\n",
    "# # Specify the input file (concatenated file)\n",
    "# input_file = 'concatenated_output.txt'\n",
    "\n",
    "# # Specify the output files (train and test)\n",
    "# output_train_file = 'train.txt'\n",
    "# output_test_file = 'test.txt'\n",
    "\n",
    "# # Read the content from the input file\n",
    "# with open(input_file, 'r', encoding='utf-8') as file:\n",
    "#     content = file.readlines()\n",
    "\n",
    "# # Shuffle the content randomly\n",
    "# random.shuffle(content)\n",
    "\n",
    "# # Determine the split ratio (e.g., 80% train, 20% test)\n",
    "# split_ratio = 0.8\n",
    "# split_index = int(len(content) * split_ratio)\n",
    "\n",
    "# # Split the content into train and test sets\n",
    "# train_data = content[:split_index]\n",
    "# test_data = content[split_index:]\n",
    "\n",
    "# # Write the train data to the output train file\n",
    "# with open(output_train_file, 'w', encoding='utf-8') as train_file:\n",
    "#     train_file.writelines(train_data)\n",
    "\n",
    "# # Write the test data to the output test file\n",
    "# with open(output_test_file, 'w', encoding='utf-8') as test_file:\n",
    "#     test_file.writelines(test_data)\n",
    "\n",
    "# print(f\"Splitting complete. Train file: {output_train_file}, Test file: {output_test_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_train = []\n",
    "for line in open(r'sentiment analytic/train.txt', 'r',encoding = 'utf-8'):\n",
    "    \n",
    "    reviews_train.append(line.strip())\n",
    "    \n",
    "reviews_test = []\n",
    "for line in open(r'sentiment analytic/test.txt', 'r',encoding = 'utf-8'):\n",
    "    \n",
    "    reviews_test.append(line.strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Despite the incredibly dire nature of several aspects of the film I found myself actually rather liking it and am a tentative fan of the film. It does require a suspension of reality on the viewers part (but surely that's what films are for) and it does turn into an enjoyable film with a twisting plot that whilst it doesn't leave you aching for more does mean that the film seems to fly by as though you are strapped into a roller-coaster instead of sat on your sofa. The special effects used are brilliant and the actual plot line and ideas put into it are fantastic. The actors play their parts superbly, particularly Woody Harrelson and it is an enjoyable movie. Adrian Helmsley (Chiwetel Ejiofor) is a scientist who warns the President that the world is in trouble. They decide to build massive arks to save the few and the world's treasures.\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_train[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPLACE_NO_SPACE = re.compile(\"(\\.)|(\\;)|(\\:)|(\\!)|(\\')|(\\?)|(\\,)|(\\\")|(\\()|(\\))|(\\[)|(\\])|(\\d+)\")\n",
    "REPLACE_WITH_SPACE = re.compile(\"(<br\\s*/><br\\s*/>)|(\\-)|(\\/)\")\n",
    "NO_SPACE = \"\"\n",
    "SPACE = \" \"\n",
    "\n",
    "def preprocess_reviews(reviews):\n",
    "    \n",
    "    reviews = [REPLACE_NO_SPACE.sub(NO_SPACE, line.lower()) for line in reviews]\n",
    "    reviews = [REPLACE_WITH_SPACE.sub(SPACE, line) for line in reviews]\n",
    "    \n",
    "    return reviews\n",
    "\n",
    "reviews_train_clean = preprocess_reviews(reviews_train)\n",
    "reviews_test_clean = preprocess_reviews(reviews_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'despite the incredibly dire nature of several aspects of the film i found myself actually rather liking it and am a tentative fan of the film it does require a suspension of reality on the viewers part but surely thats what films are for and it does turn into an enjoyable film with a twisting plot that whilst it doesnt leave you aching for more does mean that the film seems to fly by as though you are strapped into a roller coaster instead of sat on your sofa the special effects used are brilliant and the actual plot line and ideas put into it are fantastic the actors play their parts superbly particularly woody harrelson and it is an enjoyable movie adrian helmsley chiwetel ejiofor is a scientist who warns the president that the world is in trouble they decide to build massive arks to save the few and the worlds treasures'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_train_clean[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(binary=True)\n",
    "cv.fit(reviews_train_clean)\n",
    "X = cv.transform(reviews_train_clean)\n",
    "X_test = cv.transform(reviews_test_clean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target = [1 if i < 12500 else 0 for i in range(25000)]\n",
    "# print(\"Shape of X:\", X.shape)\n",
    "# print(\"Length of target:\", len(target))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (414, 3114)\n",
      "Length of target: 414\n",
      "Unique values in target: {0.0, 1.0}\n",
      "Unique classes: [0. 1.]\n",
      "Class counts: [153 157]\n",
      "Accuracy for C=0.01: 0.4423076923076923\n",
      "Unique classes: [0. 1.]\n",
      "Class counts: [153 157]\n",
      "Accuracy for C=0.05: 0.4423076923076923\n",
      "Unique classes: [0. 1.]\n",
      "Class counts: [153 157]\n",
      "Accuracy for C=0.25: 0.46153846153846156\n",
      "Unique classes: [0. 1.]\n",
      "Class counts: [153 157]\n",
      "Accuracy for C=0.5: 0.47115384615384615\n",
      "Unique classes: [0. 1.]\n",
      "Class counts: [153 157]\n",
      "Accuracy for C=1: 0.47115384615384615\n"
     ]
    }
   ],
   "source": [
    "\n",
    "target = np.concatenate((np.ones(X.shape[0] // 2), np.zeros(X.shape[0] // 2)))\n",
    "\n",
    "print(\"Shape of X:\", X.shape)\n",
    "print(\"Length of target:\", len(target))\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, target, train_size=0.75)\n",
    "\n",
    "print(\"Unique values in target:\", set(target))\n",
    "\n",
    "for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "    lr = LogisticRegression(C=c)\n",
    "    unique_classes, class_counts = np.unique(y_train, return_counts=True)\n",
    "    print(\"Unique classes:\", unique_classes)\n",
    "    print(\"Class counts:\", class_counts)\n",
    "    lr.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Accuracy for C=%s: %s\" % (c, accuracy_score(y_val, lr.predict(X_val))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "final_model = LogisticRegression(C=0.05)\n",
    "final_model.fit(X, target)\n",
    "print (\"Final Accuracy: %s\"% accuracy_score(target, final_model.predict(X_test)))\n",
    "# Final Accuracy: 0.88128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_to_coef = {word: coef for word, coef in zip(cv.get_feature_names(), final_model.coef_[0])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('excellent', 0.9283544415479621)\n",
      "('perfect', 0.794427752075745)\n",
      "('great', 0.674555321918573)\n",
      "('amazing', 0.6164834489348066)\n",
      "('superb', 0.6055919809828587)\n"
     ]
    }
   ],
   "source": [
    "for best_positive in sorted(feature_to_coef.items(),key=lambda x: x[1],reverse=True)[:5]:\n",
    "    print (best_positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('worst', -1.3679897559409033)\n",
      "('waste', -1.1688808985797163)\n",
      "('awful', -1.0273337405836442)\n",
      "('poorly', -0.8748022415442793)\n",
      "('boring', -0.8591221055443495)\n"
     ]
    }
   ],
   "source": [
    "for best_negative in sorted(feature_to_coef.items(),key=lambda x: x[1])[:5]:\n",
    "    print (best_negative)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words values are 90860\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of words values are {len(feature_to_coef)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
